{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AyLjFia_87K"
      },
      "source": [
        "<center>\n",
        "    <p style=\"text-align:center\">\n",
        "        <img alt=\"phoenix logo\" src=\"https://raw.githubusercontent.com/Arize-ai/phoenix-assets/9e6101d95936f4bd4d390efc9ce646dc6937fb2d/images/socal/github-large-banner-phoenix.jpg\" width=\"1000\"/>\n",
        "        <br>\n",
        "        <br>\n",
        "        <a href=\"https://arize.com/docs/phoenix/\">Docs</a>\n",
        "        |\n",
        "        <a href=\"https://github.com/Arize-ai/phoenix\">GitHub</a>\n",
        "        |\n",
        "        <a href=\"https://arize-ai.slack.com/join/shared_invite/zt-2w57bhem8-hq24MB6u7yE_ZF_ilOYSBw#/shared-invite/email\">Community</a>\n",
        "    </p>\n",
        "</center>\n",
        "<h1 align=\"center\">Quickstart: Datasets and Experiments</h1>\n",
        "\n",
        "Phoenix helps you run experiments over your AI and LLM applications to evaluate and iteratively improve their performance. This quickstart shows you how to get up and running quickly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RqpqcyK_878"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fctUnUb9_88D"
      },
      "source": [
        "Install Phoenix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sflwhopX_88Q",
        "outputId": "0ccec366-fafe-49fe-9d28-8af70e0f4606",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.91.0)\n",
            "Collecting httpx<0.28\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting arize-phoenix[evals]\n",
            "  Downloading arize_phoenix-11.0.0-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting aioitertools (from arize-phoenix[evals])\n",
            "  Downloading aioitertools-0.12.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting aiosqlite (from arize-phoenix[evals])\n",
            "  Downloading aiosqlite-0.21.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting alembic<2,>=1.3.0 (from arize-phoenix[evals])\n",
            "  Downloading alembic-1.16.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting arize-phoenix-client (from arize-phoenix[evals])\n",
            "  Downloading arize_phoenix_client-1.11.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting arize-phoenix-evals>=0.20.6 (from arize-phoenix[evals])\n",
            "  Downloading arize_phoenix_evals-0.21.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting arize-phoenix-otel>=0.10.3 (from arize-phoenix[evals])\n",
            "  Downloading arize_phoenix_otel-0.12.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting authlib (from arize-phoenix[evals])\n",
            "  Downloading authlib-1.6.0-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from arize-phoenix[evals]) (5.5.2)\n",
            "Collecting email-validator (from arize-phoenix[evals])\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (from arize-phoenix[evals]) (0.115.13)\n",
            "Requirement already satisfied: grpc-interceptor in /usr/local/lib/python3.11/dist-packages (from arize-phoenix[evals]) (0.15.4)\n",
            "Requirement already satisfied: grpcio in /usr/local/lib/python3.11/dist-packages (from arize-phoenix[evals]) (1.73.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from arize-phoenix[evals]) (3.1.6)\n",
            "Requirement already satisfied: numpy!=2.0.0 in /usr/local/lib/python3.11/dist-packages (from arize-phoenix[evals]) (2.0.2)\n",
            "Collecting openinference-instrumentation>=0.1.32 (from arize-phoenix[evals])\n",
            "  Downloading openinference_instrumentation-0.1.34-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting openinference-semantic-conventions>=0.1.20 (from arize-phoenix[evals])\n",
            "  Downloading openinference_semantic_conventions-0.1.21-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting opentelemetry-exporter-otlp (from arize-phoenix[evals])\n",
            "  Downloading opentelemetry_exporter_otlp-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-proto>=1.12.0 (from arize-phoenix[evals])\n",
            "  Downloading opentelemetry_proto-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-sdk (from arize-phoenix[evals])\n",
            "  Downloading opentelemetry_sdk-1.34.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting opentelemetry-semantic-conventions (from arize-phoenix[evals])\n",
            "  Downloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.11/dist-packages (from arize-phoenix[evals]) (2.2.2)\n",
            "Requirement already satisfied: protobuf<6.0,>=4.25.8 in /usr/local/lib/python3.11/dist-packages (from arize-phoenix[evals]) (5.29.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from arize-phoenix[evals]) (5.9.5)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (from arize-phoenix[evals]) (18.1.0)\n",
            "Requirement already satisfied: pydantic>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from arize-phoenix[evals]) (2.11.7)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.11/dist-packages (from arize-phoenix[evals]) (0.0.20)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from arize-phoenix[evals]) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from arize-phoenix[evals]) (1.15.3)\n",
            "Requirement already satisfied: sqlalchemy<3,>=2.0.4 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy[asyncio]<3,>=2.0.4->arize-phoenix[evals]) (2.0.41)\n",
            "Collecting sqlean-py>=3.45.1 (from arize-phoenix[evals])\n",
            "  Downloading sqlean_py-3.49.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: starlette in /usr/local/lib/python3.11/dist-packages (from arize-phoenix[evals]) (0.46.2)\n",
            "Collecting strawberry-graphql==0.270.1 (from arize-phoenix[evals])\n",
            "  Downloading strawberry_graphql-0.270.1-py3-none-any.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from arize-phoenix[evals]) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.11/dist-packages (from arize-phoenix[evals]) (4.14.0)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (from arize-phoenix[evals]) (0.34.3)\n",
            "Requirement already satisfied: wrapt>=1.17.2 in /usr/local/lib/python3.11/dist-packages (from arize-phoenix[evals]) (1.17.2)\n",
            "Collecting graphql-core<3.4.0,>=3.2.0 (from strawberry-graphql==0.270.1->arize-phoenix[evals])\n",
            "  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=23 in /usr/local/lib/python3.11/dist-packages (from strawberry-graphql==0.270.1->arize-phoenix[evals]) (24.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from strawberry-graphql==0.270.1->arize-phoenix[evals]) (2.9.0.post0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<0.28) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.28) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<0.28) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.28) (0.16.0)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic<2,>=1.3.0->arize-phoenix[evals]) (1.1.3)\n",
            "Collecting opentelemetry-api (from openinference-instrumentation>=0.1.32->arize-phoenix[evals])\n",
            "  Downloading opentelemetry_api-1.34.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0->arize-phoenix[evals]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0->arize-phoenix[evals]) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.1.0->arize-phoenix[evals]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.1.0->arize-phoenix[evals]) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.1.0->arize-phoenix[evals]) (0.4.1)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3,>=2.0.4->sqlalchemy[asyncio]<3,>=2.0.4->arize-phoenix[evals]) (3.2.3)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.11/dist-packages (from authlib->arize-phoenix[evals]) (43.0.3)\n",
            "Collecting dnspython>=2.0.0 (from email-validator->arize-phoenix[evals])\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->arize-phoenix[evals]) (3.0.2)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc==1.34.1 (from opentelemetry-exporter-otlp->arize-phoenix[evals])\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http==1.34.1 (from opentelemetry-exporter-otlp->arize-phoenix[evals])\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.34.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.34.1->opentelemetry-exporter-otlp->arize-phoenix[evals]) (1.70.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.34.1 (from opentelemetry-exporter-otlp-proto-grpc==1.34.1->opentelemetry-exporter-otlp->arize-phoenix[evals])\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: requests~=2.7 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-http==1.34.1->opentelemetry-exporter-otlp->arize-phoenix[evals]) (2.32.3)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api->openinference-instrumentation>=0.1.32->arize-phoenix[evals]) (8.7.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->arize-phoenix[evals]) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->arize-phoenix[evals]) (3.6.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn->arize-phoenix[evals]) (8.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.7.0->strawberry-graphql==0.270.1->arize-phoenix[evals]) (1.17.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography->authlib->arize-phoenix[evals]) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography->authlib->arize-phoenix[evals]) (2.22)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api->openinference-instrumentation>=0.1.32->arize-phoenix[evals]) (3.23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests~=2.7->opentelemetry-exporter-otlp-proto-http==1.34.1->opentelemetry-exporter-otlp->arize-phoenix[evals]) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests~=2.7->opentelemetry-exporter-otlp-proto-http==1.34.1->opentelemetry-exporter-otlp->arize-phoenix[evals]) (2.4.0)\n",
            "Downloading strawberry_graphql-0.270.1-py3-none-any.whl (301 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.2/301.2 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.2-py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.7/242.7 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading arize_phoenix_evals-0.21.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.2/63.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading arize_phoenix_otel-0.12.1-py3-none-any.whl (13 kB)\n",
            "Downloading openinference_instrumentation-0.1.34-py3-none-any.whl (28 kB)\n",
            "Downloading openinference_semantic_conventions-0.1.21-py3-none-any.whl (10 kB)\n",
            "Downloading opentelemetry_proto-1.34.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sqlean_py-3.49.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aioitertools-0.12.0-py3-none-any.whl (24 kB)\n",
            "Downloading aiosqlite-0.21.0-py3-none-any.whl (15 kB)\n",
            "Downloading arize_phoenix-11.0.0-py3-none-any.whl (4.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading arize_phoenix_client-1.11.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading authlib-1.6.0-py2.py3-none-any.whl (239 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.0/240.0 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Downloading opentelemetry_exporter_otlp-1.34.1-py3-none-any.whl (7.0 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_http-1.34.1-py3-none-any.whl (17 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_sdk-1.34.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl (196 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.34.1-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sqlean-py, opentelemetry-proto, openinference-semantic-conventions, graphql-core, dnspython, aiosqlite, aioitertools, strawberry-graphql, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, httpx, email-validator, alembic, opentelemetry-semantic-conventions, authlib, arize-phoenix-evals, arize-phoenix-client, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, openinference-instrumentation, opentelemetry-exporter-otlp, arize-phoenix-otel, arize-phoenix\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "firebase-admin 6.9.0 requires httpx[http2]==0.28.1, but you have httpx 0.27.2 which is incompatible.\n",
            "google-genai 1.21.1 requires httpx<1.0.0,>=0.28.1, but you have httpx 0.27.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aioitertools-0.12.0 aiosqlite-0.21.0 alembic-1.16.2 arize-phoenix-11.0.0 arize-phoenix-client-1.11.0 arize-phoenix-evals-0.21.0 arize-phoenix-otel-0.12.1 authlib-1.6.0 dnspython-2.7.0 email-validator-2.2.0 graphql-core-3.2.6 httpx-0.27.2 openinference-instrumentation-0.1.34 openinference-semantic-conventions-0.1.21 opentelemetry-api-1.34.1 opentelemetry-exporter-otlp-1.34.1 opentelemetry-exporter-otlp-proto-common-1.34.1 opentelemetry-exporter-otlp-proto-grpc-1.34.1 opentelemetry-exporter-otlp-proto-http-1.34.1 opentelemetry-proto-1.34.1 opentelemetry-sdk-1.34.1 opentelemetry-semantic-conventions-0.55b1 sqlean-py-3.49.1 strawberry-graphql-0.270.1\n"
          ]
        }
      ],
      "source": [
        "!pip install \"arize-phoenix[evals]\" openai 'httpx<0.28'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wR-rFInn_88V"
      },
      "source": [
        "Launch Phoenix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3K2t-RBG_88X"
      },
      "outputs": [],
      "source": [
        "import phoenix as px\n",
        "\n",
        "px.launch_app().view()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KanubvVz_88d"
      },
      "source": [
        "Set your OpenAI API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgGmHh14_88f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "import openai\n",
        "\n",
        "if not (openai_api_key := os.getenv(\"OPENAI_API_KEY\")):\n",
        "    openai_api_key = getpass(\"🔑 Enter your OpenAI API key: \")\n",
        "openai.api_key = openai_api_key\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5qxwgpC_88r"
      },
      "source": [
        "## Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P06fBSqa_88z"
      },
      "source": [
        "Upload a dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eIVGvrA_881"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "import phoenix as px\n",
        "\n",
        "df = pd.DataFrame(\n",
        "    [\n",
        "        {\n",
        "            \"question\": \"What is Paul Graham known for?\",\n",
        "            \"answer\": \"Co-founding Y Combinator and writing on startups and techology.\",\n",
        "            \"metadata\": {\"topic\": \"tech\"},\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "phoenix_client = px.Client()\n",
        "dataset = phoenix_client.upload_dataset(\n",
        "    dataset_name=\"test-dataset\",\n",
        "    dataframe=df,\n",
        "    input_keys=[\"question\"],\n",
        "    output_keys=[\"answer\"],\n",
        "    metadata_keys=[\"metadata\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbhIHpZN_883"
      },
      "source": [
        "## Tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iy4mbpM_884"
      },
      "source": [
        "Create a task to evaluate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpqIZq_S_885"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "openai_client = OpenAI()\n",
        "\n",
        "task_prompt_template = \"Answer in a few words: {question}\"\n",
        "\n",
        "\n",
        "def task(input) -> str:\n",
        "    question = input[\"question\"]\n",
        "    message_content = task_prompt_template.format(question=question)\n",
        "    response = openai_client.chat.completions.create(\n",
        "        model=\"gpt-4o\", messages=[{\"role\": \"user\", \"content\": message_content}]\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbHv2QCq_88_"
      },
      "source": [
        "## Evaluators"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oat1Zkmp_89E"
      },
      "source": [
        "Use pre-built evaluators to grade task output with code..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gz8uR2a_89G"
      },
      "outputs": [],
      "source": [
        "from phoenix.experiments.evaluators import ContainsAnyKeyword\n",
        "\n",
        "contains_keyword = ContainsAnyKeyword(keywords=[\"Y Combinator\", \"YC\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfyOdN-x_89H"
      },
      "source": [
        "or LLMs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZOq6icO_89I"
      },
      "outputs": [],
      "source": [
        "from phoenix.evals.models import OpenAIModel\n",
        "from phoenix.experiments.evaluators import ConcisenessEvaluator\n",
        "\n",
        "model = OpenAIModel(model=\"gpt-4o\")\n",
        "conciseness = ConcisenessEvaluator(model=model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae4EKEjw_89O"
      },
      "source": [
        "Define custom evaluators with code..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpbT3e6h_89P"
      },
      "outputs": [],
      "source": [
        "from typing import Any, Dict\n",
        "\n",
        "\n",
        "def jaccard_similarity(output: str, expected: Dict[str, Any]) -> float:\n",
        "    # https://en.wikipedia.org/wiki/Jaccard_index\n",
        "    actual_words = set(output.lower().split(\" \"))\n",
        "    expected_words = set(expected[\"answer\"].lower().split(\" \"))\n",
        "    words_in_common = actual_words.intersection(expected_words)\n",
        "    all_words = actual_words.union(expected_words)\n",
        "    return len(words_in_common) / len(all_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTpEDrLJ_89R"
      },
      "source": [
        "or LLMs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBKZfoAH_89T"
      },
      "outputs": [],
      "source": [
        "from phoenix.experiments.evaluators import create_evaluator\n",
        "\n",
        "eval_prompt_template = \"\"\"\n",
        "Given the QUESTION and REFERENCE_ANSWER, determine whether the ANSWER is accurate.\n",
        "Output only a single word (accurate or inaccurate).\n",
        "\n",
        "QUESTION: {question}\n",
        "\n",
        "REFERENCE_ANSWER: {reference_answer}\n",
        "\n",
        "ANSWER: {answer}\n",
        "\n",
        "ACCURACY (accurate / inaccurate):\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "@create_evaluator(kind=\"llm\")  # need the decorator or the kind will default to \"code\"\n",
        "def accuracy(input: Dict[str, Any], output: str, expected: Dict[str, Any]) -> float:\n",
        "    message_content = eval_prompt_template.format(\n",
        "        question=input[\"question\"], reference_answer=expected[\"answer\"], answer=output\n",
        "    )\n",
        "    response = openai_client.chat.completions.create(\n",
        "        model=\"gpt-4o\", messages=[{\"role\": \"user\", \"content\": message_content}]\n",
        "    )\n",
        "    response_message_content = response.choices[0].message.content.lower().strip()\n",
        "    return 1.0 if response_message_content == \"accurate\" else 0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7qMByu9_89U"
      },
      "source": [
        "## Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyCPfeQS_89W"
      },
      "source": [
        "Run an experiment and evaluate the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XxBnkPu_89X"
      },
      "outputs": [],
      "source": [
        "from phoenix.experiments import run_experiment\n",
        "\n",
        "experiment = run_experiment(\n",
        "    dataset,\n",
        "    task,\n",
        "    experiment_name=\"initial-experiment\",\n",
        "    evaluators=[jaccard_similarity, accuracy],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRqLYmFE_89Y"
      },
      "source": [
        "Run more evaluators after the fact."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIUYPz5m_89Z"
      },
      "outputs": [],
      "source": [
        "from phoenix.experiments import evaluate_experiment\n",
        "\n",
        "experiment = evaluate_experiment(experiment, evaluators=[contains_keyword, conciseness])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5USGuAZB_89a"
      },
      "source": [
        "And iterate 🚀"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}